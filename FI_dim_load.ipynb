{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "eaca2b5e-709b-44a4-9f4a-51c9474ef81f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import dlt\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql.types import *\n",
    " \n",
    "# =========================================\n",
    "# DATE_DIM  (Type 1 - Fixed)\n",
    "# =========================================\n",
    "# =========================================\n",
    "# DATE_DIM  (Type 1 - Fixed)\n",
    "# =========================================\n",
    "@dlt.table(\n",
    "    name=\"DATE_DIM\",\n",
    "    comment=\"Date dimension (Fixed Type 1) - Power BI Compatible\",\n",
    "    table_properties={\"quality\": \"gold\", \"dimension_type\": \"type1\"}\n",
    ")\n",
    "def date_dim():\n",
    "    df = spark.read.table(\"midterm_project.gold.food_inspections_merged\")\n",
    "    date_df = (\n",
    "        df.select(\"INSPECTION_DATE\")\n",
    "          .distinct()\n",
    "          .filter(F.col(\"INSPECTION_DATE\").isNotNull())\n",
    "          # DATE_SK as INTEGER (yyyyMMdd format)\n",
    "          .withColumn(\"DATE_SK\", \n",
    "                      F.date_format(F.col(\"INSPECTION_DATE\"), \"yyyyMMdd\").cast(\"int\"))\n",
    "          # FULL_DATE as proper DATE type (NOT STRING!)\n",
    "          .withColumn(\"FULL_DATE\", \n",
    "                      F.col(\"INSPECTION_DATE\").cast(\"date\"))\n",
    "          # Day attributes\n",
    "          .withColumn(\"DAY_NUM\", \n",
    "                      F.dayofmonth(\"INSPECTION_DATE\").cast(\"int\"))\n",
    "          .withColumn(\"WEEKDAY_ABBR\", \n",
    "                      F.date_format(\"INSPECTION_DATE\", \"E\"))\n",
    "          .withColumn(\"WEEKDAY_NAME\", \n",
    "                      F.date_format(\"INSPECTION_DATE\", \"EEEE\"))\n",
    "          .withColumn(\"WEEKDAY_NUM\", \n",
    "                      F.dayofweek(\"INSPECTION_DATE\").cast(\"int\"))\n",
    "          .withColumn(\"DAY_OF_YEAR_NUM\", \n",
    "                      F.dayofyear(\"INSPECTION_DATE\").cast(\"int\"))\n",
    "          # Week attributes\n",
    "          .withColumn(\"WEEK_OF_YEAR\", \n",
    "                      F.weekofyear(\"INSPECTION_DATE\").cast(\"int\"))\n",
    "          # Month attributes\n",
    "          .withColumn(\"MONTH_NUM\", \n",
    "                      F.month(\"INSPECTION_DATE\").cast(\"int\"))\n",
    "          .withColumn(\"MONTH_ABBR\", \n",
    "                      F.date_format(\"INSPECTION_DATE\", \"MMM\"))\n",
    "          .withColumn(\"MONTH_NAME\", \n",
    "                      F.date_format(\"INSPECTION_DATE\", \"MMMM\"))\n",
    "          # Quarter attributes\n",
    "          .withColumn(\"QUARTER_NUM\", \n",
    "                      F.quarter(\"INSPECTION_DATE\").cast(\"int\"))\n",
    "          .withColumn(\"QUARTER_NAME\", \n",
    "                      F.concat(F.lit(\"Q\"), F.quarter(\"INSPECTION_DATE\")))\n",
    "          # Year attributes\n",
    "          .withColumn(\"YEAR_NUM\", \n",
    "                      F.year(\"INSPECTION_DATE\").cast(\"int\"))\n",
    "          # Month boundaries as DATE type\n",
    "          .withColumn(\"FIRST_DAY_OF_MONTH\", \n",
    "                      F.trunc(\"INSPECTION_DATE\", \"month\").cast(\"date\"))\n",
    "          .withColumn(\"LAST_DAY_OF_MONTH\", \n",
    "                      F.last_day(\"INSPECTION_DATE\").cast(\"date\"))\n",
    "          # Weekend flag\n",
    "          .withColumn(\"IS_WEEKEND\", \n",
    "                      F.when(F.dayofweek(\"INSPECTION_DATE\").isin([1,7]), \"Y\").otherwise(\"N\"))\n",
    "          # Year-Month for sorting (as string for display, but also add numeric version)\n",
    "          .withColumn(\"YEAR_MONTH\", \n",
    "                      F.date_format(\"INSPECTION_DATE\", \"yyyy-MM\"))\n",
    "          .withColumn(\"YEAR_MONTH_NUM\", \n",
    "                      F.date_format(\"INSPECTION_DATE\", \"yyyyMM\").cast(\"int\"))\n",
    "          # Remove duplicates\n",
    "          .dropDuplicates([\"DATE_SK\"])\n",
    "          # Select columns in proper order\n",
    "          .select(\n",
    "              \"DATE_SK\",\n",
    "              \"FULL_DATE\",\n",
    "              \"DAY_NUM\",\n",
    "              \"WEEKDAY_ABBR\",\n",
    "              \"WEEKDAY_NAME\",\n",
    "              \"WEEKDAY_NUM\",\n",
    "              \"DAY_OF_YEAR_NUM\",\n",
    "              \"WEEK_OF_YEAR\",\n",
    "              \"MONTH_NUM\",\n",
    "              \"MONTH_ABBR\",\n",
    "              \"MONTH_NAME\",\n",
    "              \"QUARTER_NUM\",\n",
    "              \"QUARTER_NAME\",\n",
    "              \"YEAR_NUM\",\n",
    "              \"YEAR_MONTH\",\n",
    "              \"YEAR_MONTH_NUM\",\n",
    "              \"FIRST_DAY_OF_MONTH\",\n",
    "              \"LAST_DAY_OF_MONTH\",\n",
    "              \"IS_WEEKEND\"\n",
    "          )\n",
    "    )\n",
    "    return date_df\n",
    " \n",
    "# =========================================\n",
    "# LOCATION_DIM  (Type 1)\n",
    "# =========================================\n",
    "@dlt.table(\n",
    "    name=\"LOCATION_DIM\",\n",
    "    comment=\"Location dimension (Type 1)\",\n",
    "    table_properties={\"quality\": \"gold\", \"dimension_type\": \"type1\"}\n",
    ")\n",
    "def location_dim():\n",
    "    df = spark.read.table(\"midterm_project.gold.food_inspections_merged\")\n",
    "    loc_df = (\n",
    "        df.select(\"STREET_ADDRESS\", \"CITY\", \"STATE\", \"ZIP_CODE\", \"LATITUDE\", \"LONGITUDE\")\n",
    "          .filter(F.col(\"STREET_ADDRESS\").isNotNull())\n",
    "          .dropDuplicates([\"STREET_ADDRESS\", \"CITY\", \"STATE\", \"ZIP_CODE\"])\n",
    "          .withColumn(\"LOCATION_SK\", F.monotonically_increasing_id().cast(\"decimal(10,0)\"))\n",
    "          .withColumn(\"DI_LOAD_DT\", F.current_date())\n",
    "          .withColumn(\"DI_JOB_ID\", F.lit(\"GOLD_LOAD_001\"))\n",
    "    )\n",
    "    return loc_df\n",
    " \n",
    "# =========================================\n",
    "# BUSINESS_DIM  (Type 2 - MANUAL SCD)\n",
    "# =========================================\n",
    "# =========================================\n",
    "\n",
    "@dlt.table(\n",
    "\n",
    "    name=\"BUSINESS_DIM\",\n",
    "\n",
    "    comment=\"Business dimension with MANUAL SCD Type 2 implementation\",\n",
    "\n",
    "    table_properties={\"quality\": \"gold\", \"dimension_type\": \"type2\"}\n",
    "\n",
    ")\n",
    "\n",
    "def business_dim():\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    Manual SCD Type 2: Track historical changes to business attributes.\n",
    "\n",
    "    Creates new version when BUSINESS_NAME, AKA_NAME, or BUSINESS_TYPE changes.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    df = spark.read.table(\"midterm_project.gold.food_inspections_merged\")\n",
    "\n",
    "    # Step 1: Get all unique combinations of business attributes with their first appearance date\n",
    "\n",
    "    business_changes = (\n",
    "\n",
    "        df.select(\n",
    "\n",
    "            \"LICENSE_NUMBER\",\n",
    "\n",
    "            \"BUSINESS_NAME\",\n",
    "\n",
    "            \"AKA_NAME\",\n",
    "\n",
    "            F.col(\"FACILITY_TYPE\").alias(\"BUSINESS_TYPE\"),  # Alias here\n",
    "\n",
    "            \"INSPECTION_DATE\"\n",
    "\n",
    "        )\n",
    "\n",
    "        .filter(F.col(\"LICENSE_NUMBER\").isNotNull())\n",
    "\n",
    "        .dropDuplicates([\"LICENSE_NUMBER\", \"BUSINESS_NAME\", \"AKA_NAME\", \"BUSINESS_TYPE\"])  # ← FIXED: Use BUSINESS_TYPE\n",
    "\n",
    "    )\n",
    "\n",
    "    # Step 2: For each unique combination, get the earliest date (when this version started)\n",
    "\n",
    "    business_versions = (\n",
    "\n",
    "        business_changes\n",
    "\n",
    "        .groupBy(\"LICENSE_NUMBER\", \"BUSINESS_NAME\", \"AKA_NAME\", \"BUSINESS_TYPE\")\n",
    "\n",
    "        .agg(F.min(\"INSPECTION_DATE\").alias(\"EFFECTIVE_START_DATE\"))\n",
    "\n",
    "    )\n",
    "\n",
    "    # Step 3: Add window to determine end dates\n",
    "\n",
    "    window_spec = Window.partitionBy(\"LICENSE_NUMBER\").orderBy(\"EFFECTIVE_START_DATE\")\n",
    "\n",
    "    business_with_end_dates = (\n",
    "\n",
    "        business_versions\n",
    "\n",
    "        .withColumn(\"NEXT_START_DATE\", F.lead(\"EFFECTIVE_START_DATE\").over(window_spec))\n",
    "\n",
    "        .withColumn(\n",
    "\n",
    "            \"EFFECTIVE_END_DATE\", \n",
    "\n",
    "            F.when(F.col(\"NEXT_START_DATE\").isNotNull(), \n",
    "\n",
    "                   F.date_sub(F.col(\"NEXT_START_DATE\"), 1))\n",
    "\n",
    "            .otherwise(F.lit(None))\n",
    "\n",
    "        )\n",
    "\n",
    "        .drop(\"NEXT_START_DATE\")\n",
    "\n",
    "    )\n",
    "\n",
    "    # Step 4: Add IS_CURRENT flag and surrogate key\n",
    "\n",
    "    business_scd2 = (\n",
    "\n",
    "        business_with_end_dates\n",
    "\n",
    "        .withColumn(\n",
    "\n",
    "            \"IS_CURRENT\",\n",
    "\n",
    "            F.when(F.col(\"EFFECTIVE_END_DATE\").isNull(), \"Y\").otherwise(\"N\")\n",
    "\n",
    "        )\n",
    "\n",
    "        .withColumn(\n",
    "\n",
    "            \"VERSION_NUMBER\",\n",
    "\n",
    "            F.row_number().over(Window.partitionBy(\"LICENSE_NUMBER\").orderBy(\"EFFECTIVE_START_DATE\"))\n",
    "\n",
    "        )\n",
    "\n",
    "        .withColumn(\n",
    "\n",
    "            \"BUSINESS_SK\",\n",
    "\n",
    "            # Create a unique numeric key: LICENSE_NUMBER * 1000 + VERSION_NUMBER\n",
    "\n",
    "            (F.col(\"LICENSE_NUMBER\") * 1000 + F.col(\"VERSION_NUMBER\")).cast(\"decimal(20,0)\")\n",
    "\n",
    "        )\n",
    "\n",
    "        .withColumn(\"DI_JOB_ID\", F.lit(\"GOLD_LOAD_001\"))\n",
    "\n",
    "        .withColumn(\"DI_LOAD_DT\", F.current_date())\n",
    "\n",
    "        .select(\n",
    "\n",
    "            \"BUSINESS_SK\",\n",
    "\n",
    "            \"LICENSE_NUMBER\",\n",
    "\n",
    "            \"BUSINESS_NAME\",\n",
    "\n",
    "            \"AKA_NAME\",\n",
    "\n",
    "            \"BUSINESS_TYPE\",\n",
    "\n",
    "            \"EFFECTIVE_START_DATE\",\n",
    "\n",
    "            \"EFFECTIVE_END_DATE\",\n",
    "\n",
    "            \"IS_CURRENT\",\n",
    "\n",
    "            \"VERSION_NUMBER\",\n",
    "\n",
    "            \"DI_JOB_ID\",\n",
    "\n",
    "            \"DI_LOAD_DT\"\n",
    "\n",
    "        )\n",
    "\n",
    "    )\n",
    "\n",
    "    return business_scd2\n",
    "  \n",
    "# =========================================\n",
    "# VIOLATION_DIM  (Type 1)\n",
    "# =========================================\n",
    "@dlt.table(\n",
    "    name=\"VIOLATION_DIM\",\n",
    "    comment=\"Violation dimension (Type 1)\",\n",
    "    table_properties={\"quality\": \"gold\", \"dimension_type\": \"type1\"}\n",
    ")\n",
    "def violation_dim():\n",
    "    df = spark.read.table(\"midterm_project.gold.food_inspections_merged\")\n",
    "    viol_df = (\n",
    "        df.select(\"VIOLATION_CODE\", \"VIOLATION_DESCRIPTION\")\n",
    "          .filter(F.col(\"VIOLATION_CODE\").isNotNull())\n",
    "          .dropDuplicates([\"VIOLATION_CODE\"])\n",
    "          .withColumn(\"VIOLATION_SK\", F.monotonically_increasing_id().cast(\"decimal(10,0)\"))\n",
    "          .withColumn(\"DI_LOAD_DT\", F.current_date())\n",
    "          .withColumn(\"DI_JOB_ID\", F.lit(\"GOLD_LOAD_001\"))\n",
    "    )\n",
    "    return viol_df\n",
    " \n",
    "# =========================================\n",
    "# FACT_FOOD_INSP  (Atomic Fact Table)\n",
    "# =========================================\n",
    "@dlt.table(\n",
    "    name=\"FACT_FOOD_INSP\",\n",
    "    comment=\"Fact table - one record per inspection × violation\",\n",
    "    table_properties={\"quality\": \"gold\", \"fact_type\": \"atomic\"}\n",
    ")\n",
    "def fact_food_insp():\n",
    "    \"\"\"\n",
    "    Fact table that links to the CURRENT version of each business at time of inspection.\n",
    "    Uses inspection date to determine which business version was active.\n",
    "    \"\"\"\n",
    "    df = spark.read.table(\"midterm_project.gold.food_inspections_merged\")\n",
    "    # Read Dimension Tables\n",
    "    date_dim = dlt.read(\"DATE_DIM\").select(\"DATE_SK\", \"FULL_DATE\")\n",
    "    loc_dim = dlt.read(\"LOCATION_DIM\").select(\"LOCATION_SK\", \"STREET_ADDRESS\", \"CITY\", \"STATE\", \"ZIP_CODE\")\n",
    "    viol_dim = dlt.read(\"VIOLATION_DIM\").select(\"VIOLATION_SK\", \"VIOLATION_CODE\")\n",
    "    biz_dim = dlt.read(\"BUSINESS_DIM\").select(\n",
    "        \"BUSINESS_SK\", \n",
    "        \"LICENSE_NUMBER\", \n",
    "        \"EFFECTIVE_START_DATE\", \n",
    "        \"EFFECTIVE_END_DATE\",\n",
    "        \"IS_CURRENT\"\n",
    "    )\n",
    "    # Join with dimensions\n",
    "    # For BUSINESS_DIM: Join based on which version was active at inspection time\n",
    "    fact_df = (\n",
    "        df\n",
    "        # Join DATE_DIM\n",
    "        .join(date_dim, df.INSPECTION_DATE == date_dim.FULL_DATE, \"left\")\n",
    "        # Join LOCATION_DIM\n",
    "        .join(loc_dim,\n",
    "              (df.STREET_ADDRESS == loc_dim.STREET_ADDRESS) &\n",
    "              (df.ZIP_CODE == loc_dim.ZIP_CODE), \"left\")\n",
    "        # Join VIOLATION_DIM\n",
    "        .join(viol_dim, df.VIOLATION_CODE == viol_dim.VIOLATION_CODE, \"left\")\n",
    "        # Join BUSINESS_DIM - get the version that was active at inspection time\n",
    "        .join(\n",
    "            biz_dim,\n",
    "            (df.LICENSE_NUMBER == biz_dim.LICENSE_NUMBER) &\n",
    "            (df.INSPECTION_DATE >= biz_dim.EFFECTIVE_START_DATE) &\n",
    "            (\n",
    "                (df.INSPECTION_DATE <= biz_dim.EFFECTIVE_END_DATE) | \n",
    "                (biz_dim.EFFECTIVE_END_DATE.isNull())\n",
    "            ),\n",
    "            \"left\"\n",
    "        )\n",
    "        # Create fact columns\n",
    "        .withColumn(\"INSPECTION_SK\", F.monotonically_increasing_id().cast(\"decimal(10,0)\"))\n",
    "        .withColumn(\"DI_JOB_ID\", F.lit(\"GOLD_LOAD_001\"))\n",
    "        .withColumn(\"DI_LOAD_DT\", F.current_date())\n",
    "        .select(\n",
    "            \"INSPECTION_SK\",\n",
    "            \"LOCATION_SK\",\n",
    "            \"VIOLATION_SK\",\n",
    "            \"BUSINESS_SK\",\n",
    "            \"DATE_SK\",\n",
    "            F.col(\"INSPECTION_ID\").cast(\"decimal(30,0)\"),\n",
    "            \"INSPECTION_TYPE\",\n",
    "            \"INSPECTION_RESULT\",\n",
    "            \"RISK_LEVEL\",\n",
    "            F.col(\"INSPECTION_SCORE\").cast(\"decimal(10,0)\"),\n",
    "            \"DI_JOB_ID\",\n",
    "            \"DI_LOAD_DT\"\n",
    "        )\n",
    "        .dropDuplicates([\"INSPECTION_ID\", \"VIOLATION_SK\"])\n",
    "    )\n",
    "    return fact_df"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "FI_dim_load",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
